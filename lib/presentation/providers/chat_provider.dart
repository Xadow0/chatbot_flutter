import 'package:flutter/foundation.dart';
import 'package:shared_preferences/shared_preferences.dart';
import 'dart:io';
import 'dart:async';
import '../../domain/entities/message_entity.dart';
import '../../domain/entities/quick_response_entity.dart';
import '../../data/models/quick_response_model.dart';
import '../../data/models/remote_ollama_models.dart';
import '../../data/models/local_ollama_models.dart';
import '../../data/services/gemini_service.dart';
import '../../data/services/ollama_service.dart';
import '../../data/services/openai_service.dart';
import '../../data/services/local_ollama_service.dart';
import '../../data/services/ai_service_selector.dart';
import '../../data/services/preferences_service.dart';
import '../../data/services/ai_service_adapters.dart';
import '../../domain/usecases/command_processor.dart';
import '../../domain/repositories/iconversation_repository.dart';
import '../../domain/repositories/icommand_repository.dart';
import '../../core/constants/commands_help.dart';
import 'command_management_provider.dart';

class ChatProvider extends ChangeNotifier {
  final List<MessageEntity> _messages = [];
  List<QuickResponseEntity> _quickResponses = QuickResponseProvider.defaultResponsesAsEntities;
  bool _isProcessing = false;
  bool _isStreaming = false;
  StreamSubscription<String>? _streamSubscription;
  bool _isNewConversation = true;
  bool _isRetryingOllama = false;
  bool _ollamaSelectable = true;
  bool _needsHistoryLoad = false;

  bool _hasUnsavedChanges = false;
  File? _currentConversationFile;
  bool _isSaving = false;
  
  // ============================================================================
  // NUEVO: Control de sesi√≥n activa
  // ============================================================================
  /// Indica si hay una conversaci√≥n activa en la sesi√≥n actual.
  /// Se pone en true cuando el usuario env√≠a su primer mensaje.
  /// Se pone en false cuando el usuario crea una nueva conversaci√≥n expl√≠citamente.
  bool _hasActiveSession = false;

  late final AIServiceSelector _aiSelector;
  late final PreferencesService _preferencesService;

  final IConversationRepository _conversationRepository;
  final ICommandRepository _commandRepository;

  bool Function()? _getSyncStatus;

  CommandManagementProvider? _commandManagementProvider;

  late final GeminiService _geminiService;
  late final OllamaService _ollamaService;
  late final OpenAIService _openaiService;
  late final OllamaManagedService _localOllamaService;

  late final GeminiServiceAdapter _geminiAdapter;
  late OllamaServiceAdapter _ollamaAdapter;
  late final OpenAIServiceAdapter _openaiAdapter;
  late final LocalOllamaServiceAdapter _localOllamaAdapter;

  late CommandProcessor _commandProcessor;

  bool _showModelSelector = false;
  List<OllamaModel> _availableModels = [];
  String _currentModel = 'phi3:latest';
  AIProvider _currentProvider = AIProvider.gemini;

  static const String _groupSystemCommandsKey = 'group_system_commands';

  ChatProvider({
    required IConversationRepository conversationRepository,
    required ICommandRepository commandRepository,
    required AIServiceSelector aiServiceSelector,
  })  : _conversationRepository = conversationRepository,
        _commandRepository = commandRepository,
        _aiSelector = aiServiceSelector,
        _geminiService = aiServiceSelector.geminiService,
        _ollamaService = aiServiceSelector.ollamaService,
        _openaiService = aiServiceSelector.openaiService,
        _localOllamaService = aiServiceSelector.localOllamaService {
    _geminiAdapter = GeminiServiceAdapter(_geminiService);
    _ollamaAdapter = OllamaServiceAdapter(_ollamaService, _currentModel);
    _openaiAdapter = OpenAIServiceAdapter(_openaiService);
    _localOllamaAdapter = LocalOllamaServiceAdapter(_localOllamaService);

    _preferencesService = PreferencesService();

    _aiSelector.addListener(_onAiSelectorChanged);

    _commandProcessor = CommandProcessor(_geminiAdapter, _commandRepository);

    _initializeModels();
  }

  void setCommandManagementProvider(CommandManagementProvider provider) {
    if (_commandManagementProvider != null) {
      _commandManagementProvider!.removeListener(_onCommandDataChanged);
    }

    _commandManagementProvider = provider;
    provider.addListener(_onCommandDataChanged);

    if (!provider.isLoading) {
      _onCommandDataChanged();
    }

    debugPrint('‚úÖ [ChatProvider] Vinculado reactivamente a CommandManagementProvider');
  }

  void _onCommandDataChanged() {
    if (_commandManagementProvider == null) return;
    _updateQuickResponsesFromProvider();
  }

  void _updateQuickResponsesFromProvider() {
    if (_commandManagementProvider == null) return;

    final provider = _commandManagementProvider!;

    final organizedResponses = QuickResponseProvider.buildOrganizedResponses(
      commands: provider.commands,
      folders: provider.folders,
      groupSystemCommands: provider.groupSystemCommands,
    );

    _quickResponses = organizedResponses.map((r) => r.toEntity()).toList();
    notifyListeners();
  }

  void setSyncStatusChecker(bool Function() checker) {
    _getSyncStatus = checker;
  }

  Future<void> _onAiSelectorChanged() async {
    debugPrint('üîÑ [ChatProvider] AIServiceSelector notific√≥ cambios, actualizando UI...');

    if (_aiSelector.ollamaAvailable) {
      if (!_ollamaSelectable) {
        _ollamaSelectable = true;
        debugPrint('   üîì Ollama disponible: desbloqueando selecci√≥n en la UI');
      }

      if (!listEquals(_availableModels, _aiSelector.availableModels)) {
        _availableModels = _aiSelector.availableModels;
        debugPrint('   ‚úÖ Lista de modelos Ollama (remoto) actualizada: ${_availableModels.length} modelos');

        if (_availableModels.isNotEmpty) {
          final currentModelExists = _availableModels.any((m) => m.name == _currentModel);

          if (!currentModelExists || _currentModel.isEmpty) {
            _currentModel = _availableModels.first.name;
            _ollamaAdapter.updateModel(_currentModel);
            debugPrint('   ‚ö†Ô∏è Modelo actual no encontrado. Seleccionando por defecto: $_currentModel');
          }
        }
      }

      if (_currentProvider == AIProvider.ollama && _currentModel != _aiSelector.currentOllamaModel) {
        _currentModel = _aiSelector.currentOllamaModel;
        _ollamaAdapter.updateModel(_currentModel);
      }
    } else {
      if (_availableModels.isNotEmpty) {
        _availableModels = [];
        debugPrint('   ‚ùå Ollama (remoto) desconectado. Vaciando lista de modelos.');
      }

      if (_ollamaSelectable) {
        _ollamaSelectable = false;
        debugPrint('   üîí Bloqueando selecci√≥n de Ollama en la UI (desconectado)');
      }

      if (_currentProvider == AIProvider.ollama) {
        debugPrint('   ‚ö†Ô∏è ¬°Ollama (remoto) era el proveedor activo y se ha desconectado!');
        debugPrint('   üîÑ Cambiando autom√°ticamente a Gemini por defecto...');

        await selectProvider(AIProvider.gemini);
        debugPrint('   ‚úÖ [AIServiceSelector change] Cambio a Gemini completado.');
        _addOllamaConnectionErrorMessage();
      }
    }
    notifyListeners();
  }

  void _addOllamaConnectionErrorMessage() {
    final errorMessage = MessageEntity(
      id: DateTime.now().millisecondsSinceEpoch.toString(),
      content: '‚ùå El servidor de Ollama (remoto) se ha desconectado.\n\n'
          'Se ha cambiado autom√°ticamente a **Gemini**.\n\n'
          'Por favor, comprueba la conexi√≥n del servidor e int√©ntalo de nuevo m√°s tarde.',
      type: MessageTypeEntity.bot,
      timestamp: DateTime.now(),
    );

    if (_messages.isEmpty ||
        (_messages.last.type != MessageTypeEntity.bot) ||
        (_messages.last.content != errorMessage.content)) {
      _messages.add(errorMessage);
    }
  }

  void _updateCommandProcessor() {
    AIServiceBase currentAdapter;

    switch (_currentProvider) {
      case AIProvider.gemini:
        currentAdapter = _geminiAdapter;
        debugPrint('   üîµ Usando GeminiAdapter');
        break;
      case AIProvider.ollama:
        _ollamaAdapter.updateModel(_currentModel);
        currentAdapter = _ollamaAdapter;
        debugPrint('   üü™ Usando OllamaAdapter (remoto) con modelo: $_currentModel');
        break;
      case AIProvider.openai:
        currentAdapter = _openaiAdapter;
        debugPrint('   üü¢ Usando OpenAIAdapter');
        break;
      case AIProvider.localOllama:
        currentAdapter = _localOllamaAdapter;
        debugPrint('   üü† Usando LocalLLMAdapter (Ollama Embebido)');
        break;
    }

    _commandProcessor = CommandProcessor(currentAdapter, _commandRepository);
    debugPrint('üîÑ [ChatProvider] CommandProcessor actualizado para: $_currentProvider');
  }

  // ============================================================================
  // GETTERS
  // ============================================================================
  List<MessageEntity> get messages => List.unmodifiable(_messages);
  List<QuickResponseEntity> get quickResponses => _quickResponses;
  bool get isProcessing => _isProcessing;
  bool get isStreaming => _isStreaming;
  bool get showModelSelector => _showModelSelector;
  List<OllamaModel> get availableModels => _availableModels;
  String get currentModel => _currentModel;
  AIProvider get currentProvider => _currentProvider;
  ConnectionInfo get connectionInfo => _aiSelector.connectionInfo;
  bool get ollamaAvailable => _aiSelector.ollamaAvailable && _ollamaSelectable;
  bool get isRetryingOllama => _isRetryingOllama;
  bool get hasUnsavedChanges => _hasUnsavedChanges;
  
  // NUEVO: Getter para saber si hay una sesi√≥n activa
  bool get hasActiveSession => _hasActiveSession;
  
  /// Indica si la conversaci√≥n actual tiene contenido significativo para guardar
  /// (m√°s que solo el mensaje de bienvenida del bot)
  bool get hasSignificantContent {
    if (_messages.isEmpty) return false;
    // Si solo hay un mensaje y es del bot (bienvenida), no es significativo
    if (_messages.length == 1 && _messages.first.type == MessageTypeEntity.bot) return false;
    // Si hay al menos un mensaje del usuario, es significativo
    return _messages.any((m) => m.type == MessageTypeEntity.user);
  }

  AIServiceSelector get aiSelector => _aiSelector;
  bool get openaiAvailable => _aiSelector.openaiAvailable;
  String get currentOpenAIModel => _aiSelector.currentOpenAIModel;
  List<String> get availableOpenAIModels => _aiSelector.availableOpenAIModels;

  LocalOllamaStatus get localOllamaStatus => _aiSelector.localOllamaStatus;
  bool get localOllamaAvailable => _aiSelector.localOllamaAvailable;
  bool get localOllamaLoading => _aiSelector.localOllamaLoading;

  Stream<ConnectionInfo> get connectionStream => _aiSelector.connectionStream;

  Future<List<FileSystemEntity>> listConversations() {
    return _conversationRepository.listConversations();
  }

  Future<void> _initializeModels() async {
    try {
      debugPrint('üé¨ [ChatProvider] Inicializando modelos...');

      if (_aiSelector.ollamaAvailable) {
        _availableModels = _aiSelector.availableModels;
        if (_availableModels.isNotEmpty) {
          _currentModel = _availableModels.first.name;
          _ollamaAdapter.updateModel(_currentModel);
        }
      }

      await _restoreUserPreferences();
      await _updateQuickResponses();

      _ollamaSelectable = _aiSelector.ollamaAvailable;

      // NUEVO: A√±adir mensaje de bienvenida al inicializar si no hay mensajes
      // Esto asegura que siempre haya un mensaje inicial al abrir la app
      if (_messages.isEmpty) {
        _addWelcomeMessage();
        debugPrint('üëã [ChatProvider] Mensaje de bienvenida a√±adido en inicializaci√≥n');
      }

      notifyListeners();
    } catch (e) {
      debugPrint('‚ùå [ChatProvider] Error inicializando modelos: $e');
    }
  }

  Future<void> _restoreUserPreferences() async {
    try {
      debugPrint('üîÑ [ChatProvider] Restaurando preferencias...');

      final lastProvider = await _preferencesService.getLastProvider();

      if (lastProvider != null) {
        bool canRestore = false;

        switch (lastProvider) {
          case AIProvider.gemini:
            canRestore = true;
            break;
          case AIProvider.ollama:
            canRestore = _aiSelector.ollamaAvailable;
            if (!canRestore) {
              debugPrint('   ‚ö†Ô∏è Ollama (remoto) no disponible, usando Gemini por defecto');
            }
            break;
          case AIProvider.openai:
            canRestore = _aiSelector.openaiAvailable;
            if (!canRestore) {
              debugPrint('   ‚ö†Ô∏è OpenAI no disponible, usando Gemini por defecto');
            }
            break;
          case AIProvider.localOllama:
            canRestore = _aiSelector.localOllamaAvailable;
            if (!canRestore) {
              debugPrint('   ‚ö†Ô∏è Ollama Embebido no disponible, usando Gemini por defecto');
            }
            break;
        }

        if (canRestore) {
          _currentProvider = lastProvider;
          _updateCommandProcessor();
          debugPrint('   ‚úÖ Proveedor restaurado: $lastProvider');
        }
      }
    } catch (e) {
      debugPrint('   ‚ùå Error restaurando preferencias: $e');
    }
  }

  void toggleModelSelector() {
    debugPrint('üîÑ [ChatProvider] Toggling model selector: $_showModelSelector -> ${!_showModelSelector}');
    _showModelSelector = !_showModelSelector;
    notifyListeners();
  }

  void hideModelSelector() {
    if (_showModelSelector) {
      debugPrint('üîÑ [ChatProvider] Hiding model selector');
      _showModelSelector = false;
      notifyListeners();
    }
  }

  Future<void> selectModel(String modelName) async {
    debugPrint('üîÑ [ChatProvider] Cambiando modelo a: $modelName');

    try {
      _currentModel = modelName;
      _aiSelector.setOllamaModel(modelName);
      _ollamaAdapter.updateModel(modelName);
      hideModelSelector();
      notifyListeners();
      debugPrint('   ‚úÖ Modelo cambiado a: $modelName');
    } catch (e) {
      debugPrint('   ‚ùå Error al cambiar modelo: $e');
      _currentModel = _aiSelector.currentOllamaModel;
      notifyListeners();
    }
  }

  Future<void> selectProvider(AIProvider provider) async {
    debugPrint('üîÑ [ChatProvider] Cambiando proveedor a: $provider');

    if (provider == AIProvider.ollama && !_aiSelector.ollamaAvailable) {
      debugPrint('   ‚ùå Ollama (remoto) no disponible. No se puede seleccionar por ahora.');
      return;
    }

    bool isAvailable = false;
    switch (provider) {
      case AIProvider.gemini:
        isAvailable = true;
        break;
      case AIProvider.ollama:
        isAvailable = true;
        break;
      case AIProvider.openai:
        isAvailable = _aiSelector.openaiAvailable;
        break;
      case AIProvider.localOllama:
        isAvailable = _aiSelector.localOllamaAvailable;
        break;
    }

    if (!isAvailable) {
      debugPrint('   ‚ùå Proveedor $provider no disponible');
      return;
    }

    if (_needsHistoryLoad && _currentProvider != provider) {
      debugPrint('   üìö Detectado cambio de proveedor con historial pendiente');
      debugPrint('   üîÑ Cargando historial en el nuevo proveedor: $provider');

      final oldProvider = _currentProvider;
      _currentProvider = provider;

      _loadHistoryIntoAIService(_messages);
      _needsHistoryLoad = false;

      debugPrint('   ‚úÖ Historial transferido de $oldProvider a $provider');
    }

    _currentProvider = provider;
    await _aiSelector.setProvider(provider);
    _updateCommandProcessor();

    await _preferencesService.saveLastProvider(provider);

    hideModelSelector();
    notifyListeners();

    debugPrint('   ‚úÖ Proveedor cambiado a: $provider');
  }

  Future<void> selectOpenAIModel(String modelId) async {
    debugPrint('üîÑ [ChatProvider] Cambiando modelo OpenAI a: $modelId');

    try {
      await _aiSelector.setOpenAIModel(modelId);
      debugPrint('   ‚úÖ Modelo OpenAI cambiado a: $modelId');
    } catch (e) {
      debugPrint('   ‚ùå Error al cambiar modelo OpenAI: $e');
    }

    notifyListeners();
  }

  Future<bool> retryOllamaConnection() async {
    debugPrint('üîÑ [ChatProvider] Intentando reconectar con Ollama...');
    _isRetryingOllama = true;
    notifyListeners();

    try {
      await _ollamaService.reconnect();

      const int maxAttempts = 10;
      const Duration interval = Duration(milliseconds: 300);
      int attempts = 0;
      while (!_aiSelector.ollamaAvailable && attempts < maxAttempts) {
        await Future.delayed(interval);
        attempts++;
      }

      final bool isSuccess = _aiSelector.ollamaAvailable;

      if (isSuccess) {
        _ollamaSelectable = true;
        debugPrint('   üîì Selecci√≥n de Ollama desbloqueada (reconectado)');
        debugPrint('   ‚úÖ [ChatProvider] Reconexi√≥n exitosa. Seleccionando Ollama.');
        await selectProvider(AIProvider.ollama);
      } else {
        _ollamaSelectable = false;
        debugPrint('   ‚ùå [ChatProvider] La reconexi√≥n fall√≥.');
        if (_currentProvider != AIProvider.gemini) {
          await selectProvider(AIProvider.gemini);
        }
      }
      return isSuccess;
    } catch (e) {
      debugPrint('   ‚ùå [ChatProvider] Error durante la reconexi√≥n: $e');
      return false;
    } finally {
      _isRetryingOllama = false;
      notifyListeners();
    }
  }

  Future<void> refreshConnection() async {
    await retryOllamaConnection();
  }

  Future<LocalOllamaInitResult?> initializeLocalOllama() async {
    debugPrint('üöÄ [ChatProvider] Iniciando instalaci√≥n/configuraci√≥n de Ollama Embebido...');

    try {
      final result = await _aiSelector.initializeLocalOllama();

      if (result.success) {
        debugPrint('   ‚úÖ Ollama Embebido inicializado correctamente');
        if (_aiSelector.localOllamaAvailable) {
          await selectProvider(AIProvider.localOllama);
        }
        notifyListeners();
      } else {
        debugPrint('   ‚ùå Error en inicializaci√≥n: ${result.error}');
      }

      return result;
    } catch (e) {
      debugPrint('   ‚ùå Excepci√≥n durante inicializaci√≥n: $e');
      return null;
    }
  }

  void _addWelcomeMessage() {
    final welcomeMessage = CommandsHelp.getWelcomeMessage();

    final welcomeEntity = MessageEntity(
      id: DateTime.now().millisecondsSinceEpoch.toString(),
      content: welcomeMessage,
      type: MessageTypeEntity.bot,
      timestamp: DateTime.now(),
    );

    _messages.add(welcomeEntity);
    notifyListeners();
  }

  Future<void> refreshQuickResponses() async {
    await _updateQuickResponses();
    notifyListeners();
  }

  Future<void> _sendMessageWithStreaming(String content) async {
    debugPrint('\nüåä [ChatProvider] === ENVIANDO CON STREAMING ===');
    debugPrint('   üí¨ Contenido: ${content.length > 50 ? "${content.substring(0, 50)}..." : content}');
    debugPrint('   ü§ñ Proveedor: $_currentProvider');

    if (_needsHistoryLoad) {
      _loadHistoryIntoAIService(_messages);
      _needsHistoryLoad = false;
    }

    if (_isNewConversation) _isNewConversation = false;
    
    // NUEVO: Marcar que hay una sesi√≥n activa
    _hasActiveSession = true;
    
    hideModelSelector();

    final now = DateTime.now();
    final userMessageId = '${now.millisecondsSinceEpoch}_user';
    final botMessageId = '${now.millisecondsSinceEpoch}_bot';

    final userMessageEntity = MessageEntity(
      id: userMessageId,
      content: content,
      type: MessageTypeEntity.user,
      timestamp: now,
    );
    _messages.add(userMessageEntity);
    notifyListeners();

    _messages.add(MessageEntity(
      id: botMessageId,
      content: '',
      type: MessageTypeEntity.bot,
      timestamp: now,
    ));

    _isProcessing = true;
    _isStreaming = true;
    notifyListeners();

    final buffer = StringBuffer();
    final completer = Completer<void>();

    try {
      final adapter = _aiSelector.getCurrentAdapter();
      final stream = adapter.generateContentStream(content);

      _streamSubscription = stream.listen(
        (chunk) {
          buffer.write(chunk);

          final index = _messages.indexWhere((m) => m.id == botMessageId);
          if (index != -1) {
            _messages[index] = MessageEntity(
              id: botMessageId,
              content: buffer.toString(),
              type: MessageTypeEntity.bot,
              timestamp: now,
            );
            notifyListeners();
          }
        },
        onError: (error) {
          debugPrint('‚ùå [ChatProvider] Error en streaming: $error');

          final index = _messages.indexWhere((m) => m.id == botMessageId);
          if (index != -1) {
            _messages[index] = MessageEntity(
              id: botMessageId,
              content: buffer.isNotEmpty ? '${buffer.toString()}\n\n‚ùå Error: $error' : '‚ùå Error: $error',
              type: MessageTypeEntity.bot,
              timestamp: now,
            );
          }
          completer.complete();
        },
        onDone: () {
          debugPrint('‚úÖ [ChatProvider] Streaming completado: ${buffer.length} caracteres');
          completer.complete();
        },
        cancelOnError: true,
      );

      await completer.future;
    } catch (e) {
      debugPrint('‚ùå [ChatProvider] Error iniciando streaming: $e');

      final index = _messages.indexWhere((m) => m.id == botMessageId);
      if (index != -1) {
        _messages[index] = MessageEntity(
          id: botMessageId,
          content: '‚ùå Error: $e',
          type: MessageTypeEntity.bot,
          timestamp: now,
        );
      }
    } finally {
      _streamSubscription = null;
      _isProcessing = false;
      _isStreaming = false;
      _hasUnsavedChanges = true;
      await _updateQuickResponses();
      notifyListeners();
    }
  }

  Future<void> _sendCommandWithStreaming(String content) async {
    debugPrint('\nüåä [ChatProvider] === ENVIANDO COMANDO CON STREAMING ===');
    debugPrint('   üí¨ Comando: ${content.length > 50 ? "${content.substring(0, 50)}..." : content}');
    debugPrint('   ü§ñ Proveedor: $_currentProvider');

    hideModelSelector();
    
    // NUEVO: Marcar que hay una sesi√≥n activa
    _hasActiveSession = true;

    final now = DateTime.now();
    final userMessageId = '${now.millisecondsSinceEpoch}_user';
    final botMessageId = '${now.millisecondsSinceEpoch}_bot';

    final userMessageEntity = MessageEntity(
      id: userMessageId,
      content: content,
      type: MessageTypeEntity.user,
      timestamp: now,
    );
    _messages.add(userMessageEntity);
    notifyListeners();

    final commandResult = await _commandProcessor.processMessageStream(content);

    if (!commandResult.isCommand) {
      debugPrint('   ‚ö†Ô∏è No es comando, redirigiendo a streaming normal');
      return _sendMessageWithStreaming(content);
    }

    if (commandResult.error != null) {
      _messages.add(MessageEntity(
        id: botMessageId,
        content: '‚ö†Ô∏è ${commandResult.error}',
        type: MessageTypeEntity.bot,
        timestamp: now,
      ));
      notifyListeners();
      _hasUnsavedChanges = true;
      return;
    }

    _messages.add(MessageEntity(
      id: botMessageId,
      content: '',
      type: MessageTypeEntity.bot,
      timestamp: now,
    ));

    _isProcessing = true;
    _isStreaming = true;
    notifyListeners();

    final buffer = StringBuffer();
    final completer = Completer<void>();

    try {
      _streamSubscription = commandResult.responseStream!.listen(
        (chunk) {
          buffer.write(chunk);

          final index = _messages.indexWhere((m) => m.id == botMessageId);
          if (index != -1) {
            _messages[index] = MessageEntity(
              id: botMessageId,
              content: buffer.toString(),
              type: MessageTypeEntity.bot,
              timestamp: now,
            );
            notifyListeners();
          }
        },
        onError: (error) {
          debugPrint('‚ùå [ChatProvider] Error en comando streaming: $error');

          final index = _messages.indexWhere((m) => m.id == botMessageId);
          if (index != -1) {
            _messages[index] = MessageEntity(
              id: botMessageId,
              content: buffer.isNotEmpty ? '${buffer.toString()}\n\n‚ùå Error: $error' : '‚ùå Error: $error',
              type: MessageTypeEntity.bot,
              timestamp: now,
            );
          }
          completer.complete();
        },
        onDone: () {
          debugPrint('‚úÖ [ChatProvider] Comando streaming completado: ${buffer.length} caracteres');
          completer.complete();
        },
        cancelOnError: true,
      );

      await completer.future;
    } catch (e) {
      debugPrint('‚ùå [ChatProvider] Error iniciando comando streaming: $e');

      final index = _messages.indexWhere((m) => m.id == botMessageId);
      if (index != -1) {
        _messages[index] = MessageEntity(
          id: botMessageId,
          content: '‚ùå Error: $e',
          type: MessageTypeEntity.bot,
          timestamp: now,
        );
      }
    } finally {
      _streamSubscription = null;
      _isProcessing = false;
      _isStreaming = false;
      _hasUnsavedChanges = true;
      await _updateQuickResponses();
      notifyListeners();
    }
  }

  Future<void> sendMessage(String content) async {
    if (content.trim().isEmpty || _isProcessing) return;

    final isCommand = content.trim().startsWith('/');

    if (isCommand) {
      return _sendCommandWithStreaming(content);
    } else {
      return _sendMessageWithStreaming(content);
    }
  }

  Future<void> _updateQuickResponses() async {
    try {
      if (_commandManagementProvider != null) {
        _updateQuickResponsesFromProvider();
        return;
      }

      final allCommands = await _commandRepository.getAllCommands();
      final allFolders = await _commandRepository.getAllFolders();

      final prefs = await SharedPreferences.getInstance();
      final groupSystemCommands = prefs.getBool(_groupSystemCommandsKey) ?? false;

      final organizedResponses = QuickResponseProvider.buildOrganizedResponses(
        commands: allCommands,
        folders: allFolders,
        groupSystemCommands: groupSystemCommands,
      );

      _quickResponses = organizedResponses.map((r) => r.toEntity()).toList();

      debugPrint('üì¶ [ChatProvider] Quick responses actualizadas (fallback): ${_quickResponses.length} items');
    } catch (e) {
      debugPrint('‚ö†Ô∏è [ChatProvider] Error cargando quick responses: $e');
      _quickResponses = QuickResponseProvider.defaultResponsesAsEntities;
    }
  }

  // ============================================================================
  // NUEVO: M√©todo para iniciar una nueva conversaci√≥n expl√≠citamente
  // ============================================================================
  /// Inicia una nueva conversaci√≥n.
  /// 1. Guarda la conversaci√≥n actual si tiene contenido significativo
  /// 2. Limpia los mensajes y el historial de IA
  /// 3. Resetea el estado de la sesi√≥n
  Future<void> startNewConversation() async {
    debugPrint('üÜï [ChatProvider] Iniciando nueva conversaci√≥n...');
    
    // 1. Guardar la conversaci√≥n actual si tiene contenido
    if (hasSignificantContent && _hasUnsavedChanges) {
      debugPrint('   üíæ Guardando conversaci√≥n actual antes de crear nueva...');
      await saveCurrentConversation();
    }
    
    // 2. Limpiar todo
    _messages.clear();
    _isNewConversation = true;
    _needsHistoryLoad = false;
    _currentConversationFile = null;
    _hasUnsavedChanges = false;
    _hasActiveSession = false;
    
    // 3. Limpiar historial de servicios de IA
    _clearAIServiceHistory();
    
    // 4. A√±adir mensaje de bienvenida
    _addWelcomeMessage();
    
    notifyListeners();
    debugPrint('   ‚úÖ Nueva conversaci√≥n iniciada');
  }

  /// MODIFICADO: clearMessages ya NO inicia una nueva conversaci√≥n autom√°ticamente.
  /// Solo limpia los mensajes actuales sin guardar.
  /// Usar startNewConversation() para el flujo completo.
  Future<void> clearMessages() async {
    debugPrint('üóëÔ∏è [ChatProvider] Limpiando mensajes (sin guardar)...');

    _messages.clear();
    _isNewConversation = true;
    _needsHistoryLoad = false;
    _currentConversationFile = null;
    _hasUnsavedChanges = false;
    // NO reseteamos _hasActiveSession aqu√≠ para mantener la sesi√≥n

    _clearAIServiceHistory();
    _addWelcomeMessage();
    notifyListeners();
  }

  void _clearAIServiceHistory() {
    debugPrint('üßπ [ChatProvider] Limpiando historial de servicios de IA...');
    try {
      _geminiService.clearConversation();
    } catch (e) {
      debugPrint('   ‚ö†Ô∏è Error limpiando Gemini: $e');
    }
    try {
      _openaiService.clearConversation();
    } catch (e) {
      debugPrint('   ‚ö†Ô∏è Error limpiando OpenAI: $e');
    }
    try {
      _ollamaService.clearConversation();
    } catch (e) {
      debugPrint('   ‚ö†Ô∏è Error limpiando Ollama: $e');
    }
    try {
      _localOllamaService.clearConversation();
    } catch (e) {
      debugPrint('   ‚ö†Ô∏è Error limpiando Ollama Local: $e');
    }
  }

  Future<void> loadConversation(File file) async {
    if (_currentConversationFile != null &&
        _currentConversationFile!.path == file.path &&
        _hasUnsavedChanges) {
      debugPrint('üõë [ChatProvider] Bloqueada recarga accidental: Ya tienes esta conversaci√≥n abierta con cambios.');
      return;
    }

    debugPrint('üìÇ [ChatProvider] Cargando conversaci√≥n desde archivo...');

    try {
      final loadedMessages = await _conversationRepository.loadConversation(file);
      _messages
        ..clear()
        ..addAll(loadedMessages);

      _isNewConversation = false;
      _needsHistoryLoad = true;
      _hasActiveSession = true; // Marcar sesi√≥n activa al cargar

      _currentConversationFile = file;
      _hasUnsavedChanges = false;

      await _updateQuickResponses();
      notifyListeners();

      debugPrint('   ‚úÖ Conversaci√≥n cargada (${_messages.length} mensajes)');
    } catch (e) {
      debugPrint('‚ùå [ChatProvider] Error cargando conversaci√≥n: $e');
    }
  }

  @override
  void dispose() {
    debugPrint('üî¥ [ChatProvider] Disposing...');
    _commandManagementProvider?.removeListener(_onCommandDataChanged);

    _aiSelector.removeListener(_onAiSelectorChanged);
    _aiSelector.dispose();
    super.dispose();
  }

  void _loadHistoryIntoAIService(List<MessageEntity> messages) {
    debugPrint('üìö [ChatProvider] Cargando historial en servicio de IA...');
    debugPrint('   üéØ Proveedor actual: $_currentProvider');

    switch (_currentProvider) {
      case AIProvider.gemini:
        _loadGeminiHistory(messages);
        break;
      case AIProvider.openai:
        _loadOpenAIHistory(messages);
        break;
      case AIProvider.ollama:
        _loadOllamaHistory(messages);
        break;
      case AIProvider.localOllama:
        _loadLocalOllamaHistory(messages);
        break;
    }
  }

  void _loadGeminiHistory(List<MessageEntity> messages) {
    try {
      _geminiService.clearConversation();
      for (final message in messages) {
        if (message.type == MessageTypeEntity.user) {
          _geminiService.addUserMessage(message.content);
        } else if (message.type == MessageTypeEntity.bot) {
          _geminiService.addBotMessage(message.content);
        }
      }
      debugPrint('   ‚úÖ Historial de Gemini cargado: ${messages.length} mensajes');
    } catch (e) {
      debugPrint('   ‚ö†Ô∏è Error cargando historial en Gemini: $e');
    }
  }

  void _loadOpenAIHistory(List<MessageEntity> messages) {
    try {
      _openaiService.clearConversation();
      for (final message in messages) {
        if (message.type == MessageTypeEntity.user) {
          _openaiService.addUserMessage(message.content);
        } else if (message.type == MessageTypeEntity.bot) {
          _openaiService.addBotMessage(message.content);
        }
      }
      debugPrint('   ‚úÖ Historial de OpenAI cargado: ${messages.length} mensajes');
    } catch (e) {
      debugPrint('   ‚ö†Ô∏è Error cargando historial en OpenAI: $e');
    }
  }

  void _loadOllamaHistory(List<MessageEntity> messages) {
    try {
      _ollamaService.clearConversation();
      for (final message in messages) {
        if (message.type == MessageTypeEntity.user) {
          _ollamaService.addUserMessage(message.content);
        } else if (message.type == MessageTypeEntity.bot) {
          _ollamaService.addBotMessage(message.content);
        }
      }
      debugPrint('   ‚úÖ Historial de Ollama cargado: ${messages.length} mensajes');
    } catch (e) {
      debugPrint('   ‚ö†Ô∏è Error cargando historial en Ollama: $e');
    }
  }

  void _loadLocalOllamaHistory(List<MessageEntity> messages) {
    try {
      _localOllamaService.clearConversation();
      for (final message in messages) {
        if (message.type == MessageTypeEntity.user) {
          _localOllamaService.addUserMessage(message.content);
        } else if (message.type == MessageTypeEntity.bot) {
          _localOllamaService.addBotMessage(message.content);
        }
      }
      debugPrint('   ‚úÖ Historial de Ollama Local cargado: ${messages.length} mensajes');
    } catch (e) {
      debugPrint('   ‚ö†Ô∏è Error cargando historial en Ollama Local: $e');
    }
  }

  Future<DeleteResult> deleteAllConversations() async {
    try {
      final isSyncEnabled = _getSyncStatus?.call() ?? false;
      await _conversationRepository.deleteAllConversations();
      return DeleteResult(
        success: true,
        syncWasEnabled: isSyncEnabled,
        message: isSyncEnabled
            ? 'Todas las conversaciones eliminadas (local y nube)'
            : 'Conversaciones eliminadas localmente. Si sincronizaste previamente, permanecen en la nube.',
      );
    } catch (e) {
      return DeleteResult(
        success: false,
        syncWasEnabled: false,
        message: 'Error eliminando conversaciones: $e',
      );
    }
  }

  Future<DeleteResult> deleteConversations(List<File> files) async {
    try {
      final isSyncEnabled = _getSyncStatus?.call() ?? false;
      await _conversationRepository.deleteConversations(files);
      final count = files.length;
      return DeleteResult(
        success: true,
        syncWasEnabled: isSyncEnabled,
        message: isSyncEnabled
            ? '$count conversaci√≥n(es) eliminada(s) (local y nube)'
            : '$count conversaci√≥n(es) eliminada(s) localmente. Si sincronizaste previamente, permanecen en la nube.',
      );
    } catch (e) {
      return DeleteResult(
        success: false,
        syncWasEnabled: false,
        message: 'Error eliminando conversaciones: $e',
      );
    }
  }

  void cancelStreaming() {
    if (_isStreaming && _streamSubscription != null) {
      debugPrint('‚èπÔ∏è [ChatProvider] Cancelando streaming...');
      _streamSubscription?.cancel();
      _streamSubscription = null;
      _isProcessing = false;
      _isStreaming = false;
      _hasUnsavedChanges = true;
      notifyListeners();
      debugPrint('‚úÖ [ChatProvider] Streaming cancelado');
    }
  }

  // ============================================================================
  // NUEVO: M√©todo p√∫blico para guardar la conversaci√≥n actual
  // ============================================================================
  /// Guarda la conversaci√≥n actual de forma expl√≠cita.
  /// √ötil para llamar desde el ciclo de vida de la app.
  Future<void> saveCurrentConversation() async {
    if (_isSaving) return;
    if (!hasSignificantContent) {
      debugPrint('üíæ [ChatProvider] No hay contenido significativo para guardar');
      return;
    }
    if (!_hasUnsavedChanges) {
      debugPrint('üíæ [ChatProvider] No hay cambios sin guardar');
      return;
    }

    _isSaving = true;
    debugPrint('üíæ [ChatProvider] Guardando conversaci√≥n actual...');

    try {
      await _conversationRepository.saveConversation(
        _messages, 
        existingFile: _currentConversationFile,
      );
      _hasUnsavedChanges = false;
      debugPrint('   ‚úÖ Conversaci√≥n guardada correctamente.');
    } catch (e) {
      debugPrint('‚ùå [ChatProvider] Error al guardar conversaci√≥n: $e');
    } finally {
      _isSaving = false;
    }
  }

  /// Guarda la conversaci√≥n autom√°ticamente cuando la app pierde el foco.
  /// Este m√©todo es llamado desde el AppLifecycleObserver.
  Future<void> onAppPaused() async {
    debugPrint('‚è∏Ô∏è [ChatProvider] App pausada - verificando guardado autom√°tico...');
    await saveCurrentConversation();
  }
  
  /// Guarda la conversaci√≥n cuando la app se va a cerrar.
  /// Este m√©todo es llamado desde el AppLifecycleObserver.
  Future<void> onAppDetached() async {
    debugPrint('üîå [ChatProvider] App desconectada - guardando conversaci√≥n...');
    await saveCurrentConversation();
  }

  /// endSession ahora solo guarda, no resetea la sesi√≥n
  Future<void> endSession() async {
    if (_isSaving) return;

    if (_messages.isEmpty) return;
    if (_messages.length == 1 && _messages.first.type == MessageTypeEntity.bot) return;
    if (!_hasUnsavedChanges) return;

    _isSaving = true;
    debugPrint('üíæ [ChatProvider] Guardando sesi√≥n (Actualizaci√≥n)...');

    try {
      await _conversationRepository.saveConversation(_messages, existingFile: _currentConversationFile);

      debugPrint('   ‚úÖ Conversaci√≥n guardada/actualizada correctamente.');
    } catch (e) {
      debugPrint('‚ùå [ChatProvider] Error al guardar sesi√≥n: $e');
    } finally {
      _hasUnsavedChanges = false;
      _isSaving = false;
    }
  }
}

class DeleteResult {
  final bool success;
  final bool syncWasEnabled;
  final String message;

  DeleteResult({
    required this.success,
    required this.syncWasEnabled,
    required this.message,
  });
}